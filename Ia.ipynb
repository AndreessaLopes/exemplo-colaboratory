{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreessaLopes/exemplo-colaboratory/blob/main/Ia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10QrSe6tbogs"
      },
      "source": [
        "https://youtu.be/cEgF0YknpZw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8l2Kg-mZ1Pb"
      },
      "source": [
        "## Train custom instance segmentation model using Detectron2 - on your own dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTO_K23JaAxg"
      },
      "source": [
        "Create your own dataset by annotating for object detection using your favorite annotation software that can export annotations as COCO JSON format. I have used https://www.makesense.ai/ for my tutorial. I used the polygon tool to annotate objects and exported annotations as, \"Single file in COCO JSON format\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewiM3shDabuw"
      },
      "source": [
        "**Install Detectron2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d740Ni5JYQL7"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsePPpwZSmqt"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "\n",
        "# Atualizar detectron2\n",
        "#!python -m pip install --upgrade 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ymh1ZusxDdST"
      },
      "outputs": [],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3RUzXAwDpmi"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMQtGzZDam1Y"
      },
      "source": [
        "The default models are trained on natural images so let us go ahead and load a natural image to see if detectron is working. **We will run a pre-trained model on this image.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvNTlQtqPOTo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mie-EU7NDtzS"
      },
      "outputs": [],
      "source": [
        "im = cv2.imread(\"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/train/11.jpg\")\n",
        "cv2_imshow(im)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP7IeN5xbbUa"
      },
      "source": [
        "We create a detectron2 config and a detectron2 DefaultPredictor to run inference on this image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JoHjpRMD8eb"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo.  https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)\n",
        "outputs = predictor(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6wBmh_cEDw6"
      },
      "outputs": [],
      "source": [
        "# look at the outputs - tensors and bounding boxes.\n",
        "print(outputs[\"instances\"].pred_classes)\n",
        "print(outputs[\"instances\"].pred_boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_E7J6N9EG7L"
      },
      "outputs": [],
      "source": [
        "# We can use `Visualizer` to draw the predictions on the image.\n",
        "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=0.8)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQRQ_41Wbj3x"
      },
      "source": [
        "Now that we know the model is working on a natural image, let us test on a scientific image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PkpnJOl1BEX"
      },
      "source": [
        "Let us make some predictions. Remember that the model mask_rcnn_R_50_FPN_3x has no idea about our sample and did not get trained on cells or mitochondria or on any scientific images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa_Er1A_dNQx"
      },
      "source": [
        "Of course, our cells are mislabeled as Tie, Pizza, etc. Let us train on a custom dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2yUBzSPFPAS"
      },
      "source": [
        "# Train on a custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FikRIR7S1uEO"
      },
      "source": [
        "Import the necessary function to register datasets in the COCO format. Let us register both the training and validation datasets. Please note that we are working with training (and validation) data that is is the coco format where we have a single JSON file that describes all the annotations from all training images. <p>\n",
        "Here, we are naming our training data as 'my_dataset_train' and the validation data as 'my_dataset_val'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssw3M-5HFQ3a"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"my_dataset_train\", {}, \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/train/1807-1732.json\", \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/train\")\n",
        "register_coco_instances(\"my_dataset_val\", {}, \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/val/1580-1730.json\", \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/val\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2v-UIOU2TOF"
      },
      "source": [
        "Let us extract the metadata and dataset dictionaries for both training and validation datasets. These can be used later for other purposes, like visualization, model training, evaluation, etc. We will see a visualization example right away."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYOyee79IxHz"
      },
      "outputs": [],
      "source": [
        "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
        "train_dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlG0ZUAwK4cU"
      },
      "outputs": [],
      "source": [
        "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n",
        "val_dataset_dicts = DatasetCatalog.get(\"my_dataset_val\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNOR-qZ5LXsU"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nl5b9KPyLRfc"
      },
      "outputs": [],
      "source": [
        "# Visualize some random samples\n",
        "for d in random.sample(train_dataset_dicts, 3):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gQNZNnWLpnc"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyoliSNg2upa"
      },
      "source": [
        "Now we are ready to train a Mask R-CNN model using the Detectron2 library. We start by setting up a configuration file (.cfg) for the model. The configuration file contains many details including the output directory path, training dataset information, pre-trained weights, base learning rate, maximum number of iterations, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iPBoV69LrOE"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/models\"\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 1000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4uRTY1knqcb"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Defina o caminho para a pasta que contém as imagens\n",
        "pasta_com_imagens = '/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/train'\n",
        "\n",
        "# Defina o tamanho desejado\n",
        "desired_size = (4624, 4624)\n",
        "\n",
        "# Liste todos os arquivos na pasta\n",
        "arquivos_de_imagem = os.listdir(pasta_com_imagens)\n",
        "\n",
        "# Itere sobre os arquivos de imagem\n",
        "for arquivo in arquivos_de_imagem:\n",
        "    # Verifique se o arquivo é uma imagem (você pode ajustar a verificação de extensão conforme necessário)\n",
        "    if arquivo.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
        "        # Construa o caminho completo do arquivo\n",
        "        caminho_completo = os.path.join(pasta_com_imagens, arquivo)\n",
        "\n",
        "        # Abra a imagem\n",
        "        img = Image.open(caminho_completo)\n",
        "\n",
        "        # Redimensione a imagem para o tamanho desejado\n",
        "        img = img.resize(desired_size)\n",
        "\n",
        "        # Salve a imagem redimensionada de volta no mesmo local\n",
        "        img.save(caminho_completo)\n",
        "\n",
        "        # Feche a imagem\n",
        "        img.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCd7N_9Jil_B"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Defina o caminho para a pasta que contém as imagens\n",
        "pasta_com_imagens = '/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/val'\n",
        "\n",
        "# Defina o tamanho desejado\n",
        "desired_size = (4624, 4624)\n",
        "\n",
        "# Liste todos os arquivos na pasta\n",
        "arquivos_de_imagem = os.listdir(pasta_com_imagens)\n",
        "\n",
        "# Itere sobre os arquivos de imagem\n",
        "for arquivo in arquivos_de_imagem:\n",
        "    # Verifique se o arquivo é uma imagem (você pode ajustar a verificação de extensão conforme necessário)\n",
        "    if arquivo.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
        "        # Construa o caminho completo do arquivo\n",
        "        caminho_completo = os.path.join(pasta_com_imagens, arquivo)\n",
        "\n",
        "        # Abra a imagem\n",
        "        img = Image.open(caminho_completo)\n",
        "\n",
        "        # Redimensione a imagem para o tamanho desejado\n",
        "        img = img.resize(desired_size)\n",
        "\n",
        "        # Salve a imagem redimensionada de volta no mesmo local\n",
        "        img.save(caminho_completo)\n",
        "\n",
        "        # Feche a imagem\n",
        "        img.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrnDImFQ3XVH"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41JtQgQvybb-"
      },
      "source": [
        "Save the config file, for potential future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-lA6qbbL9qU"
      },
      "outputs": [],
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI3zLAc3yeWq"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "# Save the configuration to a config.yaml file\n",
        "# Save the configuration to a config.yaml file\n",
        "config_yaml_path = \"/content/drive/MyDrive/ColabNotebooks/models/Detectron2_Models/config.yaml\"\n",
        "with open(config_yaml_path, 'w') as file:\n",
        "    yaml.dump(cfg, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgcPBalGMB4d"
      },
      "source": [
        "# Inference & evaluation using the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyyRL4soMDdE"
      },
      "outputs": [],
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00pZTVD_WaRQ"
      },
      "source": [
        "Verify segmentation on random validation images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z8JER1KM2Ul"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "for d in random.sample(val_dataset_dicts, 3):    #select number of images for display\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=val_metadata,\n",
        "                   scale=0.5,\n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F26poTkLPQzk"
      },
      "source": [
        "Check average precision and recall. (Need more validation data than just 2 images with handful of annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQNSml38OuWV"
      },
      "outputs": [],
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"my_dataset_val\", output_dir=\"./output\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset_val\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEDbRoL3Wytv"
      },
      "source": [
        "**Load a new image and segment it.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s8VsDr-T-km"
      },
      "outputs": [],
      "source": [
        "new_im = cv2.imread(\"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/test/2030.jpeg\")\n",
        "if new_im is None:\n",
        "    print(\"Image file does not exist or path is incorrect.\")\n",
        "else:\n",
        "    outputs  = predictor(new_im)\n",
        "\n",
        "    # We can use `Visualizer` to draw the predictions on the image.\n",
        "    v = Visualizer(new_im[:, :, ::-1], metadata=train_metadata)\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95Ph5_JgXFJu"
      },
      "source": [
        "**Process multiple images in a directory and save the results in an output directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDRl7fDssgSH"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Defina o caminho para a pasta que contém as imagens\n",
        "pasta_com_imagens = '/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/test'\n",
        "\n",
        "# Defina o tamanho desejado\n",
        "desired_size = (4624, 4624)\n",
        "\n",
        "# Liste todos os arquivos na pasta\n",
        "arquivos_de_imagem = os.listdir(pasta_com_imagens)\n",
        "\n",
        "# Itere sobre os arquivos de imagem\n",
        "for arquivo in arquivos_de_imagem:\n",
        "    # Verifique se o arquivo é uma imagem (você pode ajustar a verificação de extensão conforme necessário)\n",
        "    if arquivo.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):\n",
        "        # Construa o caminho completo do arquivo\n",
        "        caminho_completo = os.path.join(pasta_com_imagens, arquivo)\n",
        "\n",
        "        # Abra a imagem\n",
        "        img = Image.open(caminho_completo)\n",
        "\n",
        "        # Redimensione a imagem para o tamanho desejado\n",
        "        img = img.resize(desired_size)\n",
        "\n",
        "        # Salve a imagem redimensionada de volta no mesmo local\n",
        "        img.save(caminho_completo)\n",
        "\n",
        "        # Feche a imagem\n",
        "        img.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSycv0yeT7IM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# Directory path to the input images folder\n",
        "input_images_directory = \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/test\"\n",
        "\n",
        "# Output directory where the segmented images will be saved\n",
        "output_directory = \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/test_results\"\n",
        "\n",
        "# Assuming 'cfg' is defined before this point\n",
        "# Load the model\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Load metadata for visualization\n",
        "train_metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
        "\n",
        "# Loop over the images in the input folder\n",
        "for image_filename in os.listdir(input_images_directory):\n",
        "    image_path = os.path.join(input_images_directory, image_filename)\n",
        "\n",
        "    # Check if the item is a file and ends with an image extension\n",
        "    if os.path.isfile(image_path) and image_filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "        new_im = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    height, width = new_im.shape[:2]\n",
        "\n",
        "    # Perform prediction on the new image\n",
        "    outputs = predictor(new_im)\n",
        "\n",
        "    # We can use `Visualizer` to draw the predictions on the image.\n",
        "    v = Visualizer(new_im[:, :, ::-1], metadata=train_metadata)\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "    # Create the output filename with \"_result\" suffix\n",
        "    result_filename = os.path.splitext(image_filename)[0] + \"_result.png\"\n",
        "    output_path = os.path.join(output_directory, result_filename)\n",
        "\n",
        "    # Save the segmented image\n",
        "    cv2.imwrite(output_path, out.get_image()[:, :, ::-1])\n",
        "\n",
        "print(\"Segmentation of all images completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoouGMEDZr24"
      },
      "source": [
        "\n",
        "**Segment images and save object level information into a csv file.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_dnA1u6Zaz8"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import cv2\n",
        "from skimage.measure import regionprops, label\n",
        "\n",
        "# Assuming you have already defined the 'predictor' object and loaded the model.\n",
        "# Also, make sure 'metadata' is defined appropriately.\n",
        "\n",
        "# Directory path to the input images folder\n",
        "input_images_directory = \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/test\"\n",
        "\n",
        "# Output directory where the CSV file will be saved\n",
        "output_csv_path = \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/test_results/output_objects.csv\"  # Add '.csv' extension to the CSV file\n",
        "\n",
        "# Check if the output_csv_path already exists\n",
        "if os.path.exists(output_csv_path):\n",
        "    # Delete the output_csv_path if it already exists\n",
        "    os.remove(output_csv_path)\n",
        "\n",
        "# Create the output_csv_path as a file\n",
        "with open(output_csv_path, 'w', newline='') as csvfile:\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "\n",
        "    # Write the header row in the CSV file\n",
        "    csvwriter.writerow([\"File Name\", \"Class Name\", \"Object Number\", \"Area\", \"Centroid\", \"BoundingBox\"])  # Add more columns as needed for other properties\n",
        "\n",
        "    # Loop over the images in the input folder\n",
        "    for image_filename in os.listdir(input_images_directory):\n",
        "        image_path = os.path.join(input_images_directory, image_filename)\n",
        "        new_im = cv2.imread(image_path)\n",
        "\n",
        "        # Perform prediction on the new image\n",
        "        if new_im is not None:\n",
        "            outputs = predictor(new_im)  # Format is documented at https://detectron2.read"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI-RtuyQ42Rv"
      },
      "source": [
        "**Generate plots to understand the objects**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h30LGnTfeIy8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the CSV file containing the object-level information\n",
        "csv_file_path = \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/test_results/output_objects.csv\"   # Update with your CSV file path\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Get class names from train_metadata.thing_classes\n",
        "class_names = train_metadata.thing_classes\n",
        "\n",
        "# Group the data by both \"File Name\" and \"Class Name\" and calculate the average number of objects per image for each class\n",
        "# first group the data by both \"File Name\" and \"Class Name\" and count the number of objects within each group.\n",
        "#Then, group the data by \"Class Name\" only and calculate the mean of the counts, which gives us the average number of objects per image for each class.\n",
        "avg_objects_per_class = df.groupby([\"File Name\", \"Class Name\"])[\"Object Number\"].count().reset_index()\n",
        "avg_objects_per_class = avg_objects_per_class.groupby(\"Class Name\")[\"Object Number\"].mean().reset_index()\n",
        "\n",
        "# Plot: Average number of objects per image for each class\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=\"Class Name\", y=\"Object Number\", data=avg_objects_per_class, ci=None, order=class_names)\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel(\"Class Name\")\n",
        "plt.ylabel(\"Average Number of Objects per Image\")\n",
        "plt.title(\"Average Number of Objects per Image for Each Class\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Group the data by class and calculate the average area of objects for each class\n",
        "avg_area_per_class = df.groupby(\"Class Name\")[\"Area\"].mean().reset_index()\n",
        "\n",
        "# Plot: Average area of objects for each class\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=\"Class Name\", y=\"Area\", data=avg_area_per_class, ci=None, order=class_names)\n",
        "plt.xticks(rotation=45)\n",
        "plt.xlabel(\"Class Name\")\n",
        "plt.ylabel(\"Average Area of Objects\")\n",
        "plt.title(\"Average Area of Objects for Each Class\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3SJXvy8idl6"
      },
      "source": [
        "**Saving binary (actually multinary) images for each class for further processing.** Here, for each input image we will save n images corresponding to the number of classes. In our example, we will save 4 images for each image corresponding to the 4 classes. Each of these images will contain objects numbered 1, 2, 3, etc. - basically instance segmentation like images. These images can be used for further downstream processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEayWBdnnku6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "# Directory path to the input images folder\n",
        "input_images_directory = \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/test\"\n",
        "\n",
        "# Output directory where the segmented images will be saved\n",
        "output_directory = \"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/test_results_instance\"  # Update this with your desired output directory\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Loop over the images in the input folder\n",
        "for image_filename in os.listdir(input_images_directory):\n",
        "    image_path = os.path.join(input_images_directory, image_filename)\n",
        "\n",
        "    # Check if the image is loaded successfully\n",
        "    new_im = cv2.imread(image_path)\n",
        "    if new_im is None:\n",
        "        print(f\"Error loading image: {image_filename}\")\n",
        "        continue\n",
        "\n",
        "    # Perform prediction on the new image\n",
        "    outputs = predictor(new_im)  # Format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "\n",
        "    # Create a dictionary to store the mask for each class with unique integer labels\n",
        "    if len(outputs[\"instances\"].pred_masks) == 0:\n",
        "      class_masks = {}\n",
        "    else:\n",
        "      class_masks = {class_name: torch.zeros_like(outputs[\"instances\"].pred_masks[0], dtype=torch.uint8, device=torch.device(\"cuda:0\"))\n",
        "                for class_name in train_metadata.thing_classes}\n",
        "\n",
        "    # Assign a unique integer label to each object in the mask\n",
        "    for i, pred_class in enumerate(outputs[\"instances\"].pred_classes):\n",
        "        class_name = train_metadata.thing_classes[pred_class]\n",
        "        class_masks[class_name] = torch.where(outputs[\"instances\"].pred_masks[i].to(device=torch.device(\"cuda:0\")),\n",
        "                                              i + 1,\n",
        "                                              class_masks[class_name])\n",
        "\n",
        "    # Save the masks for each class with unique integer labels\n",
        "    for class_name, class_mask in class_masks.items():\n",
        "        # Convert the tensor to a NumPy array and then to a regular (CPU) array\n",
        "        class_mask_np = class_mask.cpu().numpy()\n",
        "\n",
        "        # Create the output filename with _class_name_result.png extension\n",
        "        class_filename = os.path.splitext(image_filename)[0] + f\"_{class_name}_result.png\"\n",
        "        class_output_path = os.path.join(output_directory, class_filename)\n",
        "\n",
        "        # Save the image with unique integer labels\n",
        "        cv2.imwrite(class_output_path, class_mask_np.astype(np.uint8))\n",
        "\n",
        "print(\"Segmentation of all images completed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8oBbRc7Xksw"
      },
      "source": [
        "# END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yZLzRZt1Vf8"
      },
      "source": [
        "**Interested in panoptic segmentation?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOOs4M1z1pXp"
      },
      "outputs": [],
      "source": [
        "my_new_image = cv2.imread(\"/content/drive/MyDrive/Fotos - Café Maduro/training/dataset/val/2020.jpeg\")\n",
        "cv2_imshow(my_new_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDAgk8fG21sP"
      },
      "outputs": [],
      "source": [
        "# Inference with instance segmentation\n",
        "cfg_inst = get_cfg()\n",
        "cfg_inst.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg_inst.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo.  https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md\n",
        "cfg_inst.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg_inst)\n",
        "outputs = predictor(my_new_image)\n",
        "\n",
        "v = Visualizer(my_new_image[:, :, ::-1], MetadataCatalog.get(cfg_inst.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoTJ4VYx3zfn"
      },
      "source": [
        "**Panoptic segmentation = Instance segmentation + Semantic Segmentation**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBBjV3t01avh"
      },
      "outputs": [],
      "source": [
        "# Inference with a panoptic segmentation model\n",
        "cfg_pan = get_cfg()\n",
        "cfg_pan.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n",
        "cfg_pan.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg_pan)\n",
        "panoptic_seg, segments_info = predictor(my_new_image)[\"panoptic_seg\"]\n",
        "v = Visualizer(my_new_image[:, :, ::-1], MetadataCatalog.get(cfg_pan.DATASETS.TRAIN[0]), scale=1.2)\n",
        "out = v.draw_panoptic_seg_predictions(panoptic_seg.to(\"cpu\"), segments_info)\n",
        "cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}